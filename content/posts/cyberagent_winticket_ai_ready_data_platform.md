---
title: "WINTICKETにおけるAI-Readyなデータ分析基盤の構築"
date: 2025-11-20
categories: ["Data and Analytics"]
tags: ["AI Agent", "BigQuery", "Dataform", "Protocol Buffers", "Dataplex", "Devin", "WINTICKET", "CyberAgent", "Data Platform"]
author: "山田 瑠奈 (Runa Yamada)"
description: "WINTICKETにおけるAI-Readyなデータ分析基盤の構築事例。Protocol BuffersとDataformによるスキーマ駆動開発、Dataplexによるデータ品質管理、そしてDevin AIエージェントとの連携による分析自動化の取り組みを紹介。"
source: "https://developers.cyberagent.co.jp/blog/archives/59626/"
draft: false
---


**著者**: 山田 瑠奈 (Runa Yamada) (@___ryamaaa)  
**所属**: 株式会社 WinTicket / CyberAgent  
**公開日**: 2025-11-20  
**元記事**: https://developers.cyberagent.co.jp/blog/archives/59626/

## 概要

WINTICKETにおけるAI-Readyなデータ分析基盤の構築事例。Protocol BuffersとDataformによるスキーマ駆動開発、Dataplexによるデータ品質管理、そしてDevin AIエージェントとの連携による分析自動化の取り組みを紹介。導入後2ヶ月で100件近い分析依頼を処理し、データ活用のボトルネックを解消。

## この記事で学べること

- AI エージェントが自律的に分析できるデータ分析基盤の設計思想
- Protocol Buffers を起点としたスキーマ駆動開発
- Dataform によるパイプライン管理と Dataplex によるデータ品質の担保
- Devin を活用した分析自動化の実装方法

## 想定読者

- データ分析業務の効率化に興味があるエンジニア・データアナリスト
- AI エージェントの実務活用を検討している方
- データ分析基盤の設計・運用に携わっている方

---

## はじめに

WINTICKETでは競輪・オートレースのインターネット投票サービスを提供し、日々膨大なデータが蓄積されている。データマネジメントチームではAI-Readyなデータ分析基盤を整備し、AIによるデータ分析業務の効率化を目指している。本記事では、どんな設計思想でデータ分析基盤を構築し、どのようにAIエージェントを実装しているのか、現在の取り組みを紹介する。

## データ分析の課題

### 現状の課題

WINTICKETではデータを活用した意思決定が日常的に行われているが、分析に必要なドメイン知識が個々のメンバーに属人化しており、事業部メンバーで分析を完結できるのは3〜4名に限られていた。データ分析への依頼が多く発生し、回答までに数日かかることも多く、データ活用のスピードがボトルネックになっていた。

### 取り組み：SQL研修

2025年3月に事業部内で2日間のSQL研修を実施。事前にProgateでSQLの基礎を学習し、研修ではBigQueryの使い方やデータマートの構造を説明。実際のビジネス課題を題材にした問題集も作成し、データの説明やSQLのノウハウも整備した。

研修によってSQLを書けるメンバーは増えたが、自力で分析を完結できるメンバーは依然として限られていた。

【研修参加者からの声】
- 「SQLは書けるようになったが、どこにどんなデータがあるのかわからない」
- 「このカラムが具体的に何を意味しているのか、誰に聞けばいいのかわからない」
- 「どのテーブルをJOINすればいいか、どんな集計が適切かわからない」

これらの声から、SQLの構文を学ぶだけでなく、メタデータやドメイン知識へのアクセスが重要だと実感。

### 解決策：AI-Readyなデータ分析基盤の構築

この状況を打破するため、AIエージェントを活用したアプローチに着目。AIが理解しやすい形でメタデータやドメイン知識を集約し、AIが自律的に情報を参照しながら分析できる環境を構築すれば、「詳しいメンバー」の役割をAIが担えるようになる。AIが必要な情報を自動で収集して分析できれば、データサイエンティストやビジネスメンバーはより戦略的な業務に集中できる。

## データ分析基盤システム全体像

### データパイプラインの構成

WINTICKETでは、以下のようなデータパイプラインでデータを処理:

アプリケーションから送信されたイベントデータやRDBのマスターデータは、Data Lake → Data Warehouse → Data Martの3層構造で段階的に変換・集計され、最終的に様々な用途で活用できる形になる。このパイプライン全体を支えているのが、Protocol Buffersによるスキーマ管理。

### Protocol Buffersによるスキーマ管理

WINTICKETでは、Protocol Buffersでイベントスキーマを定義し、スキーマレジストリで一元管理。Protocol BuffersをSingle Source of Truthとして、以下のコンポーネントを自動生成:

1. **アプリケーションコード**: ログ送信コード（Dart、TypeScript、Goなど）
2. **ETL処理**: RDBマスターデータの抽出・変換処理
3. **Dataplex品質ルール**: Data Lake層のデータ品質チェック定義

この仕組みにより、スキーマ定義・アプリケーション・データウェアハウス・データ品質管理の一貫性が保たれ、定義の二重管理を排除。

### Dataformによるデータパイプライン管理

WINTICKETではDataformを使って、Data Lake層（生データ）→ Data Warehouse層（クレンジングや共通的な変換処理）→ Data Mart層（分析用）の3層構造でデータ変換パイプラインを管理。

Dataformのリポジトリは階層化:
- datalake/: Data Lake層の変換定義
- datawarehouse/: Data Warehouse層の変換定義（event/イベントデータ、master/マスターデータ）
- datamart/: Data Mart層の集計定義（fact/集計済ファクトテーブル、dimension/集計済ディメンションテーブル）
- assert/: データ品質チェック

### Dataplexによるデータ品質管理

DataplexでData Lake層のデータ品質チェックを自動化。Protocol Buffersで定義したBetEventを例に、自動生成される品質チェックルールを紹介:

**自動生成されるルール:**
1. user_id: 必須フィールド（required）の非NULLチェック
2. bet_amount: int64型の範囲チェック（負の値を許容しない）
3. race_category: allowed_valueで定義されたenum値チェック

品質に問題がある場合はSlackに通知する仕組みを作っており、誤ったデータで分析するリスクを削減。

これらの品質チェックルールは、Protocol Buffersの定義から自動生成。スキーマに定義されたfield_descriptionやallowed_valueといったメタデータを解析し、対応するDataplexのルールを生成することで、スキーマ定義とデータ品質管理の一貫性を保持。

## AI-Readyなデータ分析基盤の構築

### メタデータの充実でデータの意味を理解可能に

AIがデータの意味を正しく把握できるよう、Protocol BuffersとDataformでメタデータを整備。

**Protocol Buffersでのスキーマ定義:**
Protocol Buffersでイベントスキーマを定義する際、各フィールドにfield_descriptionを記述し、enum型のカラムにはallowed_valueで取りうる値とその説明を定義。

**Dataformでのメタデータ強化:**
Dataformでは、configブロックで全カラムにdescriptionを付けることをルール化。各.sqlxファイルには、SQLの定義と一緒にテーブルやカラムの説明を記述。

AIエージェントはGitHub上のProtocol BuffersやDataformリポジトリを参照し、どのテーブルがどんな処理を経て作られているか、各カラムが何を意味するかを把握。

### データ構造の明確化で適切なテーブル選択を可能に

Data Warehouse層には、マスターデータとイベントデータを合わせて100個以上のテーブルが存在。その中から分析に適したテーブルを選ぶのは、人間でも迷うことが多い。

Data Mart層に主要な集計処理ロジックを集約し、ファクトテーブル（ユーザー行動：投票、課金などのトランザクション）とディメンションテーブル（ユーザー属性・レース情報などのマスター）に分けて整理。主要な分析はData Mart層で完結できるように設計。

**テーブル利用の優先順位:**
階層構造を活かし、分析では集計済みのData Mart層から優先的に利用するという方針を定義。AIも同様に、まずData Mart層のテーブルを探索し、必要に応じてData Warehouse層を参照。

### ドキュメントの体系化でビジネスコンテキストの理解を可能に

Dataformリポジトリ内にdocs/ディレクトリを作成し、ドキュメントを体系的に整備:

**ドキュメント構成:**
- architecture/: データ構造の設計思想（overview.md全体アーキテクチャ、datamart-layer.md Data Mart層の設計方針）
- features/: 各テーブルの詳細設計（datamart/fact/ユーザー行動集計、datamart/dimension/ユーザー属性・レース情報）
- business-domain/: ビジネスドメイン知識（用語集、コーディング規則など）
- operations/: 運用手順

各テーブルの設計意図、ビジネスロジック、使用上の注意点などを記載。特にbusiness-domain/には、競輪・オートレースのビジネスモデルや投票種別（3連単、2車単など）といったWINTICKETならではのドメイン知識を蓄積。

AIはこれらを参照し、データの背景にあるビジネスコンテキストを把握。単なるテーブル定義だけでなく、「なぜこの集計が必要なのか」「どういう場面で使うべきか」といった判断も可能に。

## AIエージェントの実装

### なぜDevinを選んだのか

データ分析の自動化を実現するため、いくつかのアプローチを検討。

**検討したアプローチ:**

| アプローチ | メリット | デメリット |
|------------|----------|------------|
| フレームワークで自作（LangChain、ADKなど） | ・自由度が高い<br>・独自要件に対応可能 | ・開発・運用コストが大きい |
| エディタ支援（Cursorなど） | ・個人の作業効率化に有効<br>・導入が簡単 | ・ビジネスメンバーが使いづらい<br>・分析事例が組織に蓄積されにくい |
| Devin | ・開発・運用コストが少ない<br>・Slackから気軽に依頼できる<br>・分析事例が組織に蓄積される | ・カスタマイズの自由度が低い<br>・サービス利用料がかかる |

WINTICKETのデータマネジメントチームは少人数で運用しているため、開発・運用コストを抑えつつ、ビジネスメンバーが気軽に依頼でき、分析事例が組織に蓄積されるという点を重視し、Devinを選択。また、既に他のチームでDevinの導入が進んでおり、WINTICKET内にナレッジが蓄積されていたことも大きな決め手に。

### PlaybookとKnowledgeによる分析ワークフローの定義

Devinでは、PlaybookとKnowledgeを組み合わせて使用:

- **Playbook**: 分析の手順や実行すべきタスクを定義（「何をすべきか」）
- **Knowledge**: ドメイン知識やベストプラクティスなどの参照情報を管理（「知っておくべきこと」）

**GitHubリポジトリでの管理:**
PlaybookとKnowledgeは、WINTICKET全体でGitHubリポジトリにて一元管理:

```
devin-repository/
├── playbook/
│   └── data_analysis.md  # データ分析の手順を定義
├── knowledge/
│   ├── data_datasets.md  # データセットの説明
│   ├── data_domain_knowledge.md  # ドメイン知識（払戻ロジック等）
│   └── data_sql_best_practices.md  # SQLベストプラクティス
```

**データ分析用のPlaybook（data_analysis.md）の定義内容:**
- Devinの役割と責務
- 分析の回答フォーマット
- 運用ルール（ヒアリング、実行前確認、監査性の確保など）
- 参照すべきKnowledgeファイルの指定

**Knowledgeファイルの管理内容:**
- data_datasets.md: 推奨テーブル、データ階層構造
- data_domain_knowledge.md: 競輪・オートレース特有のビジネスロジック
- data_sql_best_practices.md: SQLのコーディング規約、パフォーマンス最適化のノウハウ

Playbookが「何をすべきか」を指示し、Knowledgeが「どのように実現するか」の参照情報を提供することで、Devinは適切に分析可能。

DevinはKnowledgeで指定された情報に加え、GitHub経由でDataformリポジトリ（business-domain/や各テーブルの定義）も参照。Knowledgeが「どのテーブルを優先すべきか」といった分析の方針を示し、Dataformリポジトリが「各テーブルの詳細な仕様」を提供することで、両者が補完。

### Slack WorkflowとMacroによる依頼の構造化

WINTICKETでは、SlackのWorkflow Builderを使って分析依頼を受付。ユーザーがフォームに「分析内容」と「分析期間」を入力すると、Devin Macroがその情報を適切なPlaybookパスとともにDevinに送信。

フォームで入力項目を決めることで、分析内容や期間といった必要な情報が漏れなくDevinに渡り、精度の高い分析が可能に。

**依頼例:**
「過去に、どの選手がだれとラインを何回組んだのか知りたい。そのようなデータはありますか？ない場合、それを推測する集計方法は何かありますか？」

### Devinによる分析の流れ

依頼を受け取ったDevinは、以下のように自律的に分析:

1. **Playbookの参照**: Macroで指定されたPlaybookから、分析に必要な情報を取得
2. **関連テーブルを検索**: GitHubのDataformリポジトリやProtocol Buffersのスキーマ定義を参照し、選手情報、レース結果、ライン情報などのテーブルを特定
3. **SQLを生成・実行**: 上記フローで得た情報を基にSQLを自動生成し、BigQueryで実行。エラーがあれば修正して再実行
4. **結果をSlackに返信**: 見やすい形式で整形し、分析結果を報告
5. **分析事例を記録**: 今回の分析パターンを記録し、次回の精度向上に活用

**実際の分析結果例:**
Devinは、データの存在を確認した上で、「最も頻繁にラインを組んだ選手ペア TOP 10」というわかりやすい形で結果をまとめ、データがあることの説明と、具体的な選手名・期別・出走日までを含めた詳細な分析結果を返信。

**導入後の効果:**
この分析自動化の仕組みを2025年9月下旬に導入して以降、10月だけで100件近い分析依頼が処理されており、導入直後から活発に活用されている。

### Knowledgeの継続的な更新

分析完了後、Slackの同じスレッド内で`!data_update_knowledge`マクロを実行すると、Devinは以下を自動で実行:

1. **分析事例の記録**: 使用したSQL、実行時間、スキャン量、使用テーブルなどをdata_devin_analysis_cases.mdに記録
2. **知見の抽出と追記**: 分析から得られた新しいドメイン知識やベストプラクティスを適切なKnowledgeファイルに追記
3. **PRの自動作成**: 更新内容をまとめたPRを作成し、データサイエンティストチームにレビューを依頼

この仕組みにより、分析のたびにKnowledgeが蓄積され、Devinの精度が継続的に向上。

## 目指す成長サイクル

Protocol Buffers、Dataform、Dataplex、そしてDevinを組み合わせることで、最終的には以下のサイクルで継続的に成長する仕組みを実現:

1. **WINTICKETメンバーが自然言語で質問**: 誰でも気軽にデータ分析を依頼
2. **AIがデータ分析**: メタデータを参照し、品質保証されたデータで分析
3. **知見が蓄積される**: 分析パターンやベストプラクティスをKnowledgeに追加
4. **分析を可視化**: よく使われる分析を特定
5. **データ分析基盤が進化**: 需要の高い分析を自動データマート化

このサイクルを回すことで、データ分析基盤とAIエージェントが共に成長していく世界を目指す。

## まとめ

本記事では、WINTICKETにおけるAI-Readyなデータ分析基盤の構築と、AIエージェントによる分析自動化の取り組みを紹介。

Devinを実際に運用してみて実感したのは、これまでデータ分析基盤で地道に積み重ねてきた取り組みが、AIエージェントの精度向上に直結しているということ。Protocol Buffersでスキーマを定義し、Dataformで全てのテーブルとカラムに説明を付けてきたこと。Data Mart層で集計定義を統一してきたこと。これらの積み重ねがあったからこそ、Devinは適切なテーブルを選択し、ビジネスロジックを理解し、SQLを生成できるようになってきている。

データ分析基盤の整備は目立たない作業が多く、効果も見えづらいが、AIエージェントを通じて、これまでの地道な取り組みが確実に効果を発揮していることを実感。

WINTICKETのデータ分析基盤構築はまだ道半ばだが、「AIがデータを活用しやすい環境」という明確なゴールに向けて、一歩ずつ進んでいる。同じような課題を抱えているチームの参考になれば幸い。

**採用情報:**
WINTICKETでは、データエンジニアを積極採用中。データ分析基盤の構築やAI活用に興味がある方は、カジュアル面談でお話しすることを歓迎。

