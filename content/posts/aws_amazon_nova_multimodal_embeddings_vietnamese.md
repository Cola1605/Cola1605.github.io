---
title: "Amazon Nova Multimodal Embeddings: M√¥ h√¨nh embedding ƒëa ph∆∞∆°ng th·ª©c t·ªëi ∆∞u cho RAG ƒë·∫°i l√Ω v√† t√¨m ki·∫øm ng·ªØ nghƒ©a"
date: 2025-11-04
categories: ["AWS", "AI", "Machine-Learning"]
tags: ["Amazon-Nova", "Embeddings", "Bedrock", "RAG", "Multimodal", "Semantic-Search"]
description: "Amazon Nova Multimodal Embeddings tr√™n Bedrock - m√¥ h√¨nh embedding th·ªëng nh·∫•t h·ªó tr·ª£ text, image, video, audio. Agentic RAG v√† semantic search v·ªõi ƒë·ªô ch√≠nh x√°c cao."
---

# Amazon Nova Multimodal Embeddings: M√¥ h√¨nh embedding ƒëa ph∆∞∆°ng th·ª©c t·ªëi ∆∞u cho RAG ƒë·∫°i l√Ω v√† t√¨m ki·∫øm ng·ªØ nghƒ©a

**T√°c gi·∫£:** Danilo Poccia  
**Ng√†y xu·∫•t b·∫£n:** 04/11/2025  
**Ngu·ªìn:** [AWS Blog](https://aws.amazon.com/jp/blogs/news/amazon-nova-multimodal-embeddings-now-available-in-amazon-bedrock/)

---

## T√≥m t·∫Øt

Ng√†y 28 th√°ng 10, Amazon ƒë√£ gi·ªõi thi·ªáu **Amazon Nova Multimodal Embeddings** - m√¥ h√¨nh embedding ƒëa ph∆∞∆°ng th·ª©c ti√™n ti·∫øn d√†nh cho c√°c ·ª©ng d·ª•ng t·∫°o sinh tƒÉng c∆∞·ªùng truy xu·∫•t ƒë·∫°i l√Ω (Agentic RAG) v√† t√¨m ki·∫øm ng·ªØ nghƒ©a. M√¥ h√¨nh n√†y hi·ªán c√≥ s·∫µn tr√™n **Amazon Bedrock**. ƒê√¢y l√† m√¥ h√¨nh embedding th·ªëng nh·∫•t ƒë·∫ßu ti√™n h·ªó tr·ª£ vƒÉn b·∫£n, t√†i li·ªáu, h√¨nh ·∫£nh, video v√† √¢m thanh th√¥ng qua m·ªôt m√¥ h√¨nh duy nh·∫•t, cho ph√©p t√¨m ki·∫øm ƒëa ph∆∞∆°ng th·ª©c v·ªõi ƒë·ªô ch√≠nh x√°c c·ª±c cao.

---

## Ph·∫ßn 1: Gi·ªõi thi·ªáu v·ªÅ Amazon Nova Multimodal Embeddings

### 1.1. Embedding l√† g√¨?

**M√¥ h√¨nh embedding** chuy·ªÉn ƒë·ªïi c√°c ƒë·∫ßu v√†o nh∆∞ vƒÉn b·∫£n, h√¨nh ·∫£nh v√† √¢m thanh th√†nh c√°c bi·ªÉu di·ªÖn s·ªë ƒë∆∞·ª£c g·ªçi l√† **"embeddings"**. Nh·ªØng embedding n√†y n·∫Øm b·∫Øt √Ω nghƒ©a ng·ªØ nghƒ©a c·ªßa ƒë·∫ßu v√†o, cho ph√©p h·ªá th·ªëng AI c√≥ th·ªÉ so s√°nh, t√¨m ki·∫øm v√† ph√¢n t√≠ch, t·ª´ ƒë√≥ tƒÉng c∆∞·ªùng c√°c tr∆∞·ªùng h·ª£p s·ª≠ d·ª•ng nh∆∞ t√¨m ki·∫øm ng·ªØ nghƒ©a v√† RAG.

### 1.2. ƒê·∫∑c ƒëi·ªÉm n·ªïi b·∫≠t c·ªßa Nova Multimodal Embeddings

**Amazon Nova Multimodal Embeddings** l√† m√¥ h√¨nh embedding ƒëa ph∆∞∆°ng th·ª©c ti√™n ti·∫øn v·ªõi c√°c ƒë·∫∑c ƒëi·ªÉm sau:

- **H·ªó tr·ª£ ƒëa ph∆∞∆°ng th·ª©c:** VƒÉn b·∫£n, t√†i li·ªáu, h√¨nh ·∫£nh, video, √¢m thanh
- **M√¥ h√¨nh th·ªëng nh·∫•t:** M·ªôt m√¥ h√¨nh duy nh·∫•t x·ª≠ l√Ω t·∫•t c·∫£ c√°c lo·∫°i n·ªôi dung
- **ƒê·ªô ch√≠nh x√°c cao:** T√¨m ki·∫øm ƒëa ph∆∞∆°ng th·ª©c v·ªõi ƒë·ªô ch√≠nh x√°c c·ª±c cao
- **Kh√¥ng gian ng·ªØ nghƒ©a th·ªëng nh·∫•t:** T·∫•t c·∫£ c√°c ph∆∞∆°ng th·ª©c ƒë∆∞·ª£c bi·ªÉu di·ªÖn trong c√πng m·ªôt kh√¥ng gian vector

---

## Ph·∫ßn 2: B·ªëi c·∫£nh v√† Th√°ch th·ª©c

### 2.1. Nhu c·∫ßu c·ªßa t·ªï ch·ª©c

C√°c t·ªï ch·ª©c ng√†y c√†ng t√¨m ki·∫øm c√°c gi·∫£i ph√°p ƒë·ªÉ tr√≠ch xu·∫•t th√¥ng tin t·ª´ d·ªØ li·ªáu phi c·∫•u tr√∫c ƒëang tƒÉng tr∆∞·ªüng li√™n t·ª•c, bao g·ªìm:

- **H√¨nh ·∫£nh s·∫£n ph·∫©m**
- **T√†i li·ªáu ch·ª©a infographic v√† vƒÉn b·∫£n**
- **Video clip do ng∆∞·ªùi d√πng t·∫£i l√™n**
- **File √¢m thanh v√† podcast**

### 2.2. H·∫°n ch·∫ø c·ªßa c√°c m√¥ h√¨nh truy·ªÅn th·ªëng

M√¥ h√¨nh embedding truy·ªÅn th·ªëng c√≥ th·ªÉ tr√≠ch xu·∫•t gi√° tr·ªã t·ª´ d·ªØ li·ªáu phi c·∫•u tr√∫c, nh∆∞ng th∆∞·ªùng **chuy√™n bi·ªát h√≥a cho m·ªôt lo·∫°i n·ªôi dung duy nh·∫•t**. ƒêi·ªÅu n√†y d·∫´n ƒë·∫øn c√°c h·∫°n ch·∫ø:

#### ‚ùå H·∫°n ch·∫ø ch√≠nh:

1. **Ph·∫£i x√¢y d·ª±ng gi·∫£i ph√°p embedding ƒëa ph∆∞∆°ng th·ª©c ph·ª©c t·∫°p**
2. **B·ªã gi·ªõi h·∫°n v√†o c√°c tr∆∞·ªùng h·ª£p s·ª≠ d·ª•ng chuy√™n bi·ªát cho m·ªôt lo·∫°i n·ªôi dung**
3. **Kh√≥ n·∫Øm b·∫Øt quan h·ªá ƒëa ph∆∞∆°ng th·ª©c hi·ªáu qu·∫£** trong:
   - T√†i li·ªáu c√≥ vƒÉn b·∫£n v√† h√¨nh ·∫£nh xen k·∫Ω
   - Video ch·ª©a c√°c y·∫øu t·ªë h√¨nh ·∫£nh, √¢m thanh v√† vƒÉn b·∫£n

### 2.3. Gi·∫£i ph√°p c·ªßa Nova Multimodal Embeddings

**Nova Multimodal Embeddings** h·ªó tr·ª£ kh√¥ng gian ng·ªØ nghƒ©a th·ªëng nh·∫•t cho vƒÉn b·∫£n, t√†i li·ªáu, h√¨nh ·∫£nh, video v√† √¢m thanh trong c√°c tr∆∞·ªùng h·ª£p s·ª≠ d·ª•ng nh∆∞:

‚úÖ **T√¨m ki·∫øm ƒëa ph∆∞∆°ng th·ª©c gi·ªØa c√°c n·ªôi dung h·ªón h·ª£p**  
‚úÖ **T√¨m ki·∫øm b·∫±ng h√¨nh ·∫£nh tham chi·∫øu**  
‚úÖ **Truy xu·∫•t t√†i li·ªáu tr·ª±c quan**  
‚úÖ **Ph√¢n t√≠ch n·ªôi dung ƒëa ph∆∞∆°ng th·ª©c**

---

## Ph·∫ßn 3: Hi·ªáu su·∫•t v√† ƒê√°nh gi√°

### 3.1. K·∫øt qu·∫£ Benchmark

Qua ƒë√°nh gi√° tr√™n nhi·ªÅu benchmark kh√°c nhau, m√¥ h√¨nh ƒë√£ ƒë·∫°t ƒë∆∞·ª£c **ƒë·ªô ch√≠nh x√°c v∆∞·ª£t tr·ªôi** c√≥ th·ªÉ s·ª≠ d·ª•ng ngay l·∫≠p t·ª©c.

![Amazon Nova Embeddings „ÅÆ„Éô„É≥„ÉÅ„Éû„Éº„ÇØ](https://d2908q01vomqb2.cloudfront.net/da4b9237bacccdf19c0760cab7aec4a8359010b0/2025/10/28/nova-multimodal-embeddings-benchmarks-with-notes-1024x642.png)

*B·∫£ng k·∫øt qu·∫£ benchmark c·ªßa Amazon Nova Embeddings*

### 3.2. C√°c t√≠nh nƒÉng ch√≠nh

#### üìä ƒê·ªô d√†i ng·ªØ c·∫£nh:
- **VƒÉn b·∫£n:** T·ªëi ƒëa 8K tokens
- **Video/√Çm thanh:** T·ªëi ƒëa 30 gi√¢y m·ªói segment

#### üåç H·ªó tr·ª£ ng√¥n ng·ªØ:
- T·ªëi ƒëa **200 ng√¥n ng·ªØ**

#### üîÑ API:
- **API ƒë·ªìng b·ªô:** Cho ·ª©ng d·ª•ng real-time
- **API b·∫•t ƒë·ªìng b·ªô:** Cho x·ª≠ l√Ω n·ªôi dung l·ªõn

#### ‚úÇÔ∏è Segmentation (Chunking):
- Ph√¢n chia vƒÉn b·∫£n d√†i, video, v√† √¢m thanh th√†nh c√°c segment d·ªÖ qu·∫£n l√Ω
- T·∫°o embedding cho t·ª´ng ph·∫ßn

#### üìê C√°c k√≠ch th∆∞·ªõc ƒë·∫ßu ra:
- **3,072 dimensions** - Bi·ªÉu di·ªÖn chi ti·∫øt nh·∫•t
- **1,024 dimensions** - C√¢n b·∫±ng gi·ªØa ƒë·ªô ch√≠nh x√°c v√† hi·ªáu qu·∫£
- **384 dimensions** - Hi·ªáu su·∫•t t√¨m ki·∫øm t·ªët
- **256 dimensions** - S·ª≠ d·ª•ng t√†i nguy√™n t·ªëi thi·ªÉu

C√°c k√≠ch th∆∞·ªõc n√†y ƒë∆∞·ª£c hu·∫•n luy·ªán b·∫±ng **Matryoshka Representation Learning (MRL)**, cho ph√©p t√¨m ki·∫øm end-to-end v·ªõi ƒë·ªô tr·ªÖ th·∫•p trong khi gi·∫£m thi·ªÉu s·ª± bi·∫øn ƒë·ªông v·ªÅ ƒë·ªô ch√≠nh x√°c.

---

## Ph·∫ßn 4: H∆∞·ªõng d·∫´n S·ª≠ d·ª•ng

### 4.1. B·∫Øt ƒë·∫ßu v·ªõi Text Embedding

Nova Multimodal Embeddings tu√¢n theo c√πng m·∫´u nh∆∞ c√°c m√¥ h√¨nh kh√°c tr√™n Amazon Bedrock. M√¥ h√¨nh nh·∫≠n ƒë·∫ßu v√†o l√† vƒÉn b·∫£n, t√†i li·ªáu, h√¨nh ·∫£nh, video ho·∫∑c √¢m thanh, v√† tr·∫£ v·ªÅ c√°c embedding s·ªë c√≥ th·ªÉ s·ª≠ d·ª•ng cho t√¨m ki·∫øm ng·ªØ nghƒ©a, so s√°nh ƒë·ªô t∆∞∆°ng t·ª± ho·∫∑c RAG.

#### V√≠ d·ª• v·ªõi AWS SDK for Python (Boto3):

```python
import json
import boto3

MODEL_ID = "amazon.nova-2-multimodal-embeddings-v1:0"
EMBEDDING_DIMENSION = 3072

# Kh·ªüi t·∫°o Amazon Bedrock runtime client
bedrock_runtime = boto3.client("bedrock-runtime", region_name="us-east-1")

print(f"Generating text embedding with {MODEL_ID}...")

# VƒÉn b·∫£n c·∫ßn embedding
text = "Amazon Nova is a multimodal foundation model"

# T·∫°o embedding
request_body = {
    "taskType": "SINGLE_EMBEDDING",
    "singleEmbeddingParams": {
        "embeddingPurpose": "GENERIC_INDEX",
        "embeddingDimension": EMBEDDING_DIMENSION,
        "text": {"truncationMode": "END", "value": text},
    },
}

response = bedrock_runtime.invoke_model(
    body=json.dumps(request_body),
    modelId=MODEL_ID,
    contentType="application/json",
)

# Tr√≠ch xu·∫•t embedding
response_body = json.loads(response["body"].read())
embedding = response_body["embeddings"][0]["embedding"]

print(f"Generated embedding with {len(embedding)} dimensions")
```

#### üíæ L∆∞u tr·ªØ v√† truy xu·∫•t:

ƒê·ªÉ l∆∞u tr·ªØ v√† truy xu·∫•t embedding hi·ªáu qu·∫£, b·∫°n c√≥ th·ªÉ s·ª≠ d·ª•ng **Amazon S3 Vectors** - l∆∞u tr·ªØ t·ªëi ∆∞u chi ph√≠ h·ªó tr·ª£ l∆∞u tr·ªØ v√† truy v·∫•n vector ·ªü m·ªçi quy m√¥.

---

### 4.2. Image Embedding

Nova Multimodal Embeddings c√≥ th·ªÉ n·∫Øm b·∫Øt c·∫£ ng·ªØ c·∫£nh vƒÉn b·∫£n v√† h√¨nh ·∫£nh v√†o m·ªôt embedding duy nh·∫•t, cho ph√©p hi·ªÉu t√†i li·ªáu s√¢u h∆°n.

#### C√°ch s·ª≠ d·ª•ng `embeddingPurpose`:

- **Khi t·∫°o index:** ƒê·∫∑t `GENERIC_INDEX`
- **Khi truy v·∫•n:** ƒê·∫∑t theo lo·∫°i m·ª•c c·∫ßn truy xu·∫•t
  - V√≠ d·ª•: `DOCUMENT_RETRIEVAL` cho truy xu·∫•t t√†i li·ªáu

#### V√≠ d·ª• embedding h√¨nh ·∫£nh:

```python
import base64

print(f"Generating image embedding with {MODEL_ID}...")

# ƒê·ªçc v√† encode h√¨nh ·∫£nh
with open("photo.jpg", "rb") as f:
    image_bytes = base64.b64encode(f.read()).decode("utf-8")

# T·∫°o embedding
request_body = {
    "taskType": "SINGLE_EMBEDDING",
    "singleEmbeddingParams": {
        "embeddingPurpose": "GENERIC_INDEX",
        "embeddingDimension": EMBEDDING_DIMENSION,
        "image": {
            "format": "jpeg",
            "source": {"bytes": image_bytes}
        },
    },
}

response = bedrock_runtime.invoke_model(
    body=json.dumps(request_body),
    modelId=MODEL_ID,
    contentType="application/json",
)

# Tr√≠ch xu·∫•t embedding
response_body = json.loads(response["body"].read())
embedding = response_body["embeddings"][0]["embedding"]

print(f"Generated embedding with {len(embedding)} dimensions")
```

---

### 4.3. Video Embedding (API b·∫•t ƒë·ªìng b·ªô)

X·ª≠ l√Ω n·ªôi dung video s·ª≠ d·ª•ng **API b·∫•t ƒë·ªìng b·ªô**, ƒë√¢y l√† y√™u c·∫ßu cho video l·ªõn h∆°n 25 MB khi ƒë∆∞·ª£c encode b·∫±ng Base64.

#### Quy tr√¨nh:

1. **Upload video l√™n S3 bucket** trong c√πng AWS Region
2. **T·∫°o job embedding b·∫•t ƒë·ªìng b·ªô**
3. **Polling cho ƒë·∫øn khi job ho√†n th√†nh**
4. **L·∫•y k·∫øt qu·∫£ embedding t·ª´ S3**

#### Upload video l√™n S3:

```bash
aws s3 cp presentation.mp4 s3://my-video-bucket/videos/
```

#### T·∫°o job embedding video:

V√≠ d·ª• n√†y cho th·∫•y c√°ch tr√≠ch xu·∫•t th√¥ng tin embedding t·ª´ c·∫£ th√†nh ph·∫ßn h√¨nh ·∫£nh v√† √¢m thanh c·ªßa file video. T√≠nh nƒÉng segmentation cho ph√©p chia video d√†i th√†nh c√°c chunk d·ªÖ qu·∫£n l√Ω, cho ph√©p t√¨m ki·∫øm hi·ªáu qu·∫£ n·ªôi dung video k√©o d√†i nhi·ªÅu gi·ªù.

```python
# Kh·ªüi t·∫°o Amazon S3 client
s3 = boto3.client("s3", region_name="us-east-1")

print(f"Generating video embedding with {MODEL_ID}...")

# Amazon S3 URI
S3_VIDEO_URI = "s3://my-video-bucket/videos/presentation.mp4"
S3_EMBEDDING_DESTINATION_URI = "s3://my-embedding-destination-bucket/embeddings-output/"

# T·∫°o job embedding b·∫•t ƒë·ªìng b·ªô cho video c√≥ √¢m thanh
model_input = {
    "taskType": "SEGMENTED_EMBEDDING",
    "segmentedEmbeddingParams": {
        "embeddingPurpose": "GENERIC_INDEX",
        "embeddingDimension": EMBEDDING_DIMENSION,
        "video": {
            "format": "mp4",
            "embeddingMode": "AUDIO_VIDEO_COMBINED",
            "source": {
                "s3Location": {"uri": S3_VIDEO_URI}
            },
            "segmentationConfig": {
                "durationSeconds": 15  # Chia th√†nh c√°c chunk 15 gi√¢y
            },
        },
    },
}

response = bedrock_runtime.start_async_invoke(
    modelId=MODEL_ID,
    modelInput=model_input,
    outputDataConfig={
        "s3OutputDataConfig": {
            "s3Uri": S3_EMBEDDING_DESTINATION_URI
        }
    },
)

invocation_arn = response["invocationArn"]
print(f"Async job started: {invocation_arn}")

# Polling cho ƒë·∫øn khi job ho√†n th√†nh
print("\nPolling for job completion...")
while True:
    job = bedrock_runtime.get_async_invoke(invocationArn=invocation_arn)
    status = job["status"]
    print(f"Status: {status}")
    
    if status != "InProgress":
        break
    
    time.sleep(15)

# Ki·ªÉm tra xem job c√≥ ho√†n th√†nh th√†nh c√¥ng kh√¥ng
if status == "Completed":
    output_s3_uri = job["outputDataConfig"]["s3OutputDataConfig"]["s3Uri"]
    print(f"\nSuccess! Embeddings at: {output_s3_uri}")
    
    # Parse S3 URI ƒë·ªÉ l·∫•y bucket v√† prefix
    s3_uri_parts = output_s3_uri[5:].split("/", 1)  # Lo·∫°i b·ªè prefix "s3://"
    bucket = s3_uri_parts[0]
    prefix = s3_uri_parts[1] if len(s3_uri_parts) > 1 else ""
    
    # Mode AUDIO_VIDEO_COMBINED xu·∫•t ra embedding-audio-video.jsonl
    embeddings_key = f"{prefix}/embedding-audio-video.jsonl".lstrip("/")
    print(f"Reading embeddings from: s3://{bucket}/{embeddings_key}")
    
    # ƒê·ªçc v√† parse file JSONL
    response = s3.get_object(Bucket=bucket, Key=embeddings_key)
    content = response['Body'].read().decode('utf-8')
    
    embeddings = []
    for line in content.strip().split('\n'):
        if line:
            embeddings.append(json.loads(line))
    
    print(f"\nFound {len(embeddings)} video segments:")
    for i, segment in enumerate(embeddings):
        print(f"  Segment {i}: {segment.get('startTime', 0):.1f}s - {segment.get('endTime', 0):.1f}s")
        print(f"    Embedding dimension: {len(segment.get('embedding', []))}")
else:
    print(f"\nJob failed: {job.get('failureMessage', 'Unknown error')}")
```

---

### 4.4. Thi·∫øt l·∫≠p Vector Store v·ªõi Amazon S3 Vectors

Sau khi t·∫°o embedding, b·∫°n c·∫ßn m·ªôt n∆°i ƒë·ªÉ l∆∞u tr·ªØ v√† truy xu·∫•t ch√∫ng hi·ªáu qu·∫£. Amazon S3 Vectors cung c·∫•p c∆° s·ªü h·∫° t·∫ßng c·∫ßn thi·∫øt cho t√¨m ki·∫øm ƒë·ªô t∆∞∆°ng t·ª± quy m√¥ l·ªõn.

#### C√°c t√≠nh nƒÉng ch√≠nh:

‚úÖ **N·ªôi dung t∆∞∆°ng t·ª± v·ªÅ ng·ªØ nghƒ©a ƒë∆∞·ª£c cluster t·ª± nhi√™n**  
‚úÖ **T·∫°o index c√≥ th·ªÉ t√¨m ki·∫øm**  
‚úÖ **S·ª≠ d·ª•ng metadata ƒë·ªÉ ch·ªâ ƒë·ªãnh ƒë·ªãnh d·∫°ng g·ªëc v√† n·ªôi dung c·∫ßn t·∫°o index**

#### V√≠ d·ª• thi·∫øt l·∫≠p vector store:

```python
# Kh·ªüi t·∫°o Amazon S3 Vectors client
s3vectors = boto3.client("s3vectors", region_name="us-east-1")

# C·∫•u h√¨nh
VECTOR_BUCKET = "my-vector-store"
INDEX_NAME = "embeddings"

# T·∫°o vector bucket v√† index (n·∫øu ch∆∞a t·ªìn t·∫°i)
try:
    s3vectors.get_vector_bucket(vectorBucketName=VECTOR_BUCKET)
    print(f"Vector bucket {VECTOR_BUCKET} already exists")
except s3vectors.exceptions.NotFoundException:
    s3vectors.create_vector_bucket(vectorBucketName=VECTOR_BUCKET)
    print(f"Created vector bucket: {VECTOR_BUCKET}")

try:
    s3vectors.get_index(vectorBucketName=VECTOR_BUCKET, indexName=INDEX_NAME)
    print(f"Vector index {INDEX_NAME} already exists")
except s3vectors.exceptions.NotFoundException:
    s3vectors.create_index(
        vectorBucketName=VECTOR_BUCKET,
        indexName=INDEX_NAME,
        dimension=EMBEDDING_DIMENSION,
        dataType="float32",
        distanceMetric="cosine"
    )
    print(f"Created index: {INDEX_NAME}")

# Danh s√°ch vƒÉn b·∫£n m·∫´u
texts = [
    "Machine learning on AWS",
    "Amazon Bedrock provides foundation models",
    "S3 Vectors enables semantic search"
]

print(f"\nGenerating embeddings for {len(texts)} texts...")

# T·∫°o embedding cho m·ªói vƒÉn b·∫£n b·∫±ng Amazon Nova
vectors = []
for text in texts:
    response = bedrock_runtime.invoke_model(
        body=json.dumps({
            "taskType": "SINGLE_EMBEDDING",
            "singleEmbeddingParams": {
                "embeddingDimension": EMBEDDING_DIMENSION,
                "text": {"truncationMode": "END", "value": text}
            }
        }),
        modelId=MODEL_ID,
        accept="application/json",
        contentType="application/json"
    )
    
    response_body = json.loads(response["body"].read())
    embedding = response_body["embeddings"][0]["embedding"]
    
    vectors.append({
        "key": f"text:{text[:50]}",  # ƒê·ªãnh danh duy nh·∫•t
        "data": {"float32": embedding},
        "metadata": {"type": "text", "content": text}
    })
    
    print(f"  ‚úì Generated embedding for: {text}")

# Th√™m t·∫•t c·∫£ c√°c vector c·∫ßn l∆∞u trong m·ªôt l·∫ßn g·ªçi
s3vectors.put_vectors(
    vectorBucketName=VECTOR_BUCKET,
    indexName=INDEX_NAME,
    vectors=vectors
)

print(f"\nSuccessfully added {len(vectors)} vectors to the store in one put_vectors call!")
```

---

### 4.5. Cross-Modal Search (T√¨m ki·∫øm ƒëa ph∆∞∆°ng th·ª©c)

**Cross-modal search** l√† m·ªôt trong nh·ªØng l·ª£i √≠ch quan tr·ªçng nh·∫•t c·ªßa multimodal embeddings. B·∫°n c√≥ th·ªÉ t√¨m ki·∫øm nhi·ªÅu lo·∫°i n·ªôi dung kh√°c nhau b·∫±ng m·ªôt truy v·∫•n duy nh·∫•t v√† t√¨m n·ªôi dung t∆∞∆°ng t·ª± nh·∫•t, b·∫•t k·ªÉ n√≥ ƒë∆∞·ª£c t·∫°o t·ª´ vƒÉn b·∫£n, h√¨nh ·∫£nh, video hay √¢m thanh.

#### C√°c tr∆∞·ªùng h·ª£p s·ª≠ d·ª•ng:

‚úÖ **Truy v·∫•n b·∫±ng vƒÉn b·∫£n ƒë·ªÉ t√¨m h√¨nh ·∫£nh li√™n quan**  
‚úÖ **T√¨m ki·∫øm video b·∫±ng m√¥ t·∫£ vƒÉn b·∫£n**  
‚úÖ **T√¨m audio clip ph√π h·ª£p v·ªõi ch·ªß ƒë·ªÅ c·ª• th·ªÉ**  
‚úÖ **Ph√°t hi·ªán t√†i li·ªáu d·ª±a tr√™n n·ªôi dung h√¨nh ·∫£nh v√† vƒÉn b·∫£n**

#### V√≠ d·ª• t√¨m ki·∫øm:

```python
# VƒÉn b·∫£n truy v·∫•n
query_text = "foundation models"

print(f"\nGenerating embeddings for query '{query_text}' ...")

# T·∫°o embedding cho truy v·∫•n
response = bedrock_runtime.invoke_model(
    body=json.dumps({
        "taskType": "SINGLE_EMBEDDING",
        "singleEmbeddingParams": {
            "embeddingPurpose": "GENERIC_RETRIEVAL",
            "embeddingDimension": EMBEDDING_DIMENSION,
            "text": {"truncationMode": "END", "value": query_text}
        }
    }),
    modelId=MODEL_ID,
    accept="application/json",
    contentType="application/json"
)

response_body = json.loads(response["body"].read())
query_embedding = response_body["embeddings"][0]["embedding"]

print(f"Searching for similar embeddings...\n")

# T√¨m ki·∫øm 5 vector t∆∞∆°ng t·ª± nh·∫•t
response = s3vectors.query_vectors(
    vectorBucketName=VECTOR_BUCKET,
    indexName=INDEX_NAME,
    queryVector={"float32": query_embedding},
    topK=5,
    returnDistance=True,
    returnMetadata=True
)

# Hi·ªÉn th·ªã k·∫øt qu·∫£
print(f"Found {len(response['vectors'])} results:\n")

for i, result in enumerate(response["vectors"], 1):
    print(f"{i}. {result['key']}")
    print(f"  Distance: {result['distance']:.4f}")
    if result.get("metadata"):
        print(f"  Metadata: {result['metadata']}")
    print()
```

**Distance score** gi√∫p b·∫°n hi·ªÉu m·ª©c ƒë·ªô li√™n quan c·ªßa k·∫øt qu·∫£ v·ªõi truy v·∫•n g·ªëc.

---

### 4.6. Script ho√†n ch·ªânh

D∆∞·ªõi ƒë√¢y l√† script ho√†n ch·ªânh t·ªïng h·ª£p t·∫•t c·∫£ c√°c v√≠ d·ª• tr√™n:

```python
import json
import base64
import time
import boto3

MODEL_ID = "amazon.nova-2-multimodal-embeddings-v1:0"
EMBEDDING_DIMENSION = 3072

# Kh·ªüi t·∫°o Amazon Bedrock runtime client
bedrock_runtime = boto3.client("bedrock-runtime", region_name="us-east-1")

# ===== TEXT EMBEDDING =====
print(f"Generating text embedding with {MODEL_ID}...")

text = "Amazon Nova is a multimodal foundation model"

request_body = {
    "taskType": "SINGLE_EMBEDDING",
    "singleEmbeddingParams": {
        "embeddingPurpose": "GENERIC_INDEX",
        "embeddingDimension": EMBEDDING_DIMENSION,
        "text": {"truncationMode": "END", "value": text},
    },
}

response = bedrock_runtime.invoke_model(
    body=json.dumps(request_body),
    modelId=MODEL_ID,
    contentType="application/json",
)

response_body = json.loads(response["body"].read())
embedding = response_body["embeddings"][0]["embedding"]
print(f"Generated embedding with {len(embedding)} dimensions")

# ===== IMAGE EMBEDDING =====
print(f"Generating image embedding with {MODEL_ID}...")

with open("photo.jpg", "rb") as f:
    image_bytes = base64.b64encode(f.read()).decode("utf-8")

request_body = {
    "taskType": "SINGLE_EMBEDDING",
    "singleEmbeddingParams": {
        "embeddingPurpose": "GENERIC_INDEX",
        "embeddingDimension": EMBEDDING_DIMENSION,
        "image": {
            "format": "jpeg",
            "source": {"bytes": image_bytes}
        },
    },
}

response = bedrock_runtime.invoke_model(
    body=json.dumps(request_body),
    modelId=MODEL_ID,
    contentType="application/json",
)

response_body = json.loads(response["body"].read())
embedding = response_body["embeddings"][0]["embedding"]
print(f"Generated embedding with {len(embedding)} dimensions")

# ===== VIDEO EMBEDDING (ASYNC) =====
s3 = boto3.client("s3", region_name="us-east-1")

print(f"Generating video embedding with {MODEL_ID}...")

S3_VIDEO_URI = "s3://my-video-bucket/videos/presentation.mp4"
S3_EMBEDDING_DESTINATION_URI = "s3://my-video-bucket/embeddings-output/"

model_input = {
    "taskType": "SEGMENTED_EMBEDDING",
    "segmentedEmbeddingParams": {
        "embeddingPurpose": "GENERIC_INDEX",
        "embeddingDimension": EMBEDDING_DIMENSION,
        "video": {
            "format": "mp4",
            "embeddingMode": "AUDIO_VIDEO_COMBINED",
            "source": {
                "s3Location": {"uri": S3_VIDEO_URI}
            },
            "segmentationConfig": {
                "durationSeconds": 15
            },
        },
    },
}

response = bedrock_runtime.start_async_invoke(
    modelId=MODEL_ID,
    modelInput=model_input,
    outputDataConfig={
        "s3OutputDataConfig": {
            "s3Uri": S3_EMBEDDING_DESTINATION_URI
        }
    },
)

invocation_arn = response["invocationArn"]
print(f"Async job started: {invocation_arn}")

print("\nPolling for job completion...")
while True:
    job = bedrock_runtime.get_async_invoke(invocationArn=invocation_arn)
    status = job["status"]
    print(f"Status: {status}")
    
    if status != "InProgress":
        break
    
    time.sleep(15)

if status == "Completed":
    output_s3_uri = job["outputDataConfig"]["s3OutputDataConfig"]["s3Uri"]
    print(f"\nSuccess! Embeddings at: {output_s3_uri}")
    
    s3_uri_parts = output_s3_uri[5:].split("/", 1)
    bucket = s3_uri_parts[0]
    prefix = s3_uri_parts[1] if len(s3_uri_parts) > 1 else ""
    
    embeddings_key = f"{prefix}/embedding-audio-video.jsonl".lstrip("/")
    print(f"Reading embeddings from: s3://{bucket}/{embeddings_key}")
    
    response = s3.get_object(Bucket=bucket, Key=embeddings_key)
    content = response['Body'].read().decode('utf-8')
    
    embeddings = []
    for line in content.strip().split('\n'):
        if line:
            embeddings.append(json.loads(line))
    
    print(f"\nFound {len(embeddings)} video segments:")
    for i, segment in enumerate(embeddings):
        print(f"  Segment {i}: {segment.get('startTime', 0):.1f}s - {segment.get('endTime', 0):.1f}s")
        print(f"    Embedding dimension: {len(segment.get('embedding', []))}")
else:
    print(f"\nJob failed: {job.get('failureMessage', 'Unknown error')}")

# ===== VECTOR STORE SETUP (S3 VECTORS) =====
s3vectors = boto3.client("s3vectors", region_name="us-east-1")

VECTOR_BUCKET = "my-vector-store"
INDEX_NAME = "embeddings"

try:
    s3vectors.get_vector_bucket(vectorBucketName=VECTOR_BUCKET)
    print(f"Vector bucket {VECTOR_BUCKET} already exists")
except s3vectors.exceptions.NotFoundException:
    s3vectors.create_vector_bucket(vectorBucketName=VECTOR_BUCKET)
    print(f"Created vector bucket: {VECTOR_BUCKET}")

try:
    s3vectors.get_index(vectorBucketName=VECTOR_BUCKET, indexName=INDEX_NAME)
    print(f"Vector index {INDEX_NAME} already exists")
except s3vectors.exceptions.NotFoundException:
    s3vectors.create_index(
        vectorBucketName=VECTOR_BUCKET,
        indexName=INDEX_NAME,
        dimension=EMBEDDING_DIMENSION,
        dataType="float32",
        distanceMetric="cosine"
    )
    print(f"Created index: {INDEX_NAME}")

texts = [
    "Machine learning on AWS",
    "Amazon Bedrock provides foundation models",
    "S3 Vectors enables semantic search"
]

print(f"\nGenerating embeddings for {len(texts)} texts...")

vectors = []
for text in texts:
    response = bedrock_runtime.invoke_model(
        body=json.dumps({
            "taskType": "SINGLE_EMBEDDING",
            "singleEmbeddingParams": {
                "embeddingPurpose": "GENERIC_INDEX",
                "embeddingDimension": EMBEDDING_DIMENSION,
                "text": {"truncationMode": "END", "value": text}
            }
        }),
        modelId=MODEL_ID,
        accept="application/json",
        contentType="application/json"
    )
    
    response_body = json.loads(response["body"].read())
    embedding = response_body["embeddings"][0]["embedding"]
    
    vectors.append({
        "key": f"text:{text[:50]}",
        "data": {"float32": embedding},
        "metadata": {"type": "text", "content": text}
    })
    
    print(f"  ‚úì Generated embedding for: {text}")

s3vectors.put_vectors(
    vectorBucketName=VECTOR_BUCKET,
    indexName=INDEX_NAME,
    vectors=vectors
)

print(f"\nSuccessfully added {len(vectors)} vectors to the store in one put_vectors call!")

# ===== CROSS-MODAL SEARCH =====
query_text = "foundation models"

print(f"\nGenerating embeddings for query '{query_text}' ...")

response = bedrock_runtime.invoke_model(
    body=json.dumps({
        "taskType": "SINGLE_EMBEDDING",
        "singleEmbeddingParams": {
            "embeddingPurpose": "GENERIC_RETRIEVAL",
            "embeddingDimension": EMBEDDING_DIMENSION,
            "text": {"truncationMode": "END", "value": query_text}
        }
    }),
    modelId=MODEL_ID,
    accept="application/json",
    contentType="application/json"
)

response_body = json.loads(response["body"].read())
query_embedding = response_body["embeddings"][0]["embedding"]

print(f"Searching for similar embeddings...\n")

response = s3vectors.query_vectors(
    vectorBucketName=VECTOR_BUCKET,
    indexName=INDEX_NAME,
    queryVector={"float32": query_embedding},
    topK=5,
    returnDistance=True,
    returnMetadata=True
)

print(f"Found {len(response['vectors'])} results:\n")

for i, result in enumerate(response["vectors"], 1):
    print(f"{i}. {result['key']}")
    print(f"  Distance: {result['distance']:.4f}")
    if result.get("metadata"):
        print(f"  Metadata: {result['metadata']}")
    print()
```

---

## Ph·∫ßn 5: Nh·ªØng ƒëi·ªÅu c·∫ßn bi·∫øt

### 5.1. C√°c t√πy ch·ªçn Dimension ƒë·∫ßu ra

Nova Multimodal Embeddings cung c·∫•p 4 t√πy ch·ªçn dimension ƒë·∫ßu ra:

| Dimension | ƒê·∫∑c ƒëi·ªÉm | Use case |
|-----------|----------|----------|
| **3,072** | Bi·ªÉu di·ªÖn chi ti·∫øt nh·∫•t, c·∫ßn nhi·ªÅu l∆∞u tr·ªØ v√† t√≠nh to√°n | ·ª®ng d·ª•ng y√™u c·∫ßu ƒë·ªô ch√≠nh x√°c cao nh·∫•t |
| **1,024** | C√¢n b·∫±ng gi·ªØa ƒë·ªô ch√≠nh x√°c v√† hi·ªáu qu·∫£ | H·∫ßu h·∫øt c√°c ·ª©ng d·ª•ng s·∫£n xu·∫•t |
| **384** | Hi·ªáu su·∫•t t√¨m ki·∫øm v√† hi·ªáu qu·∫£ t√†i nguy√™n th·ª±c t·∫ø | ·ª®ng d·ª•ng c·∫ßn t·ªëi ∆∞u hi·ªáu su·∫•t |
| **256** | S·ª≠ d·ª•ng t√†i nguy√™n t·ªëi thi·ªÉu | ·ª®ng d·ª•ng c√≥ gi·ªõi h·∫°n t√†i nguy√™n |

T√≠nh linh ho·∫°t n√†y gi√∫p b·∫°n t·ªëi ∆∞u h√≥a cho c√°c y√™u c·∫ßu ·ª©ng d·ª•ng v√† chi ph√≠ c·ª• th·ªÉ.

### 5.2. H·ªó tr·ª£ ƒë·ªô d√†i ng·ªØ c·∫£nh

M√¥ h√¨nh c√≥ th·ªÉ x·ª≠ l√Ω ng·ªØ c·∫£nh kh√° d√†i:

#### VƒÉn b·∫£n:
- T·ªëi ƒëa **8,192 tokens** m·ªói l·∫ßn

#### Video v√† √Çm thanh:
- T·ªëi ƒëa **30 gi√¢y** m·ªói segment
- M√¥ h√¨nh c√≥ th·ªÉ ph√¢n ƒëo·∫°n c√°c file d√†i h∆°n

#### T√≠nh nƒÉng Segmentation:
- ƒê·∫∑c bi·ªát h·ªØu √≠ch khi x·ª≠ l√Ω file media l·ªõn
- Chia file th√†nh c√°c ph·∫ßn d·ªÖ qu·∫£n l√Ω
- T·∫°o embedding cho m·ªói segment
- Cho ph√©p t√¨m ki·∫øm hi·ªáu qu·∫£ n·ªôi dung k√©o d√†i nhi·ªÅu gi·ªù

### 5.3. C√°c t√≠nh nƒÉng Responsible AI

M√¥ h√¨nh bao g·ªìm c√°c t√≠nh nƒÉng Responsible AI ƒë∆∞·ª£c t√≠ch h·ª£p trong Amazon Bedrock:

‚úÖ **Content Safety Filter:** N·ªôi dung g·ª≠i ƒë·ªÉ embedding ƒëi qua b·ªô l·ªçc an to√†n n·ªôi dung c·ªßa Amazon Bedrock  
‚úÖ **Fairness Measures:** C√°c bi·ªán ph√°p c√¥ng b·∫±ng ƒë·ªÉ gi·∫£m thi·ªÉu bias

### 5.4. API ƒë·ªìng b·ªô v√† b·∫•t ƒë·ªìng b·ªô

#### API ƒë·ªìng b·ªô:
- **S·ª≠ d·ª•ng cho:** ·ª®ng d·ª•ng real-time c·∫ßn ph·∫£n h·ªìi ngay l·∫≠p t·ª©c
- **V√≠ d·ª•:** X·ª≠ l√Ω truy v·∫•n ng∆∞·ªùi d√πng trong giao di·ªán t√¨m ki·∫øm

#### API b·∫•t ƒë·ªìng b·ªô:
- **S·ª≠ d·ª•ng cho:** X·ª≠ l√Ω n·ªôi dung l·ªõn v·ªõi √≠t ·∫£nh h∆∞·ªüng v·ªÅ ƒë·ªô tr·ªÖ
- **V√≠ d·ª•:** X·ª≠ l√Ω video v√† c√°c workload kh√°c

---

## Ph·∫ßn 6: T√≠ch h·ª£p trong M√¥i tr∆∞·ªùng Production

### 6.1. C√°c t√πy ch·ªçn l∆∞u tr·ªØ Vector Database

Trong ·ª©ng d·ª•ng production, embedding c√≥ th·ªÉ ƒë∆∞·ª£c l∆∞u tr·ªØ trong b·∫•t k·ª≥ vector database n√†o.

#### C√°c t√πy ch·ªçn ƒë∆∞·ª£c khuy·∫øn ngh·ªã:

##### 1. Amazon OpenSearch Service
- **T√≠ch h·ª£p native** v·ªõi Nova Multimodal Embeddings t·∫°i th·ªùi ƒëi·ªÉm ra m·∫Øt
- X√¢y d·ª±ng ·ª©ng d·ª•ng t√¨m ki·∫øm c√≥ kh·∫£ nƒÉng m·ªü r·ªông d·ªÖ d√†ng
- Ph√π h·ª£p cho: ·ª®ng d·ª•ng t√¨m ki·∫øm quy m√¥ l·ªõn

##### 2. Amazon S3 Vectors
- L∆∞u tr·ªØ v√† truy v·∫•n embedding d·ªÖ d√†ng b·∫±ng d·ªØ li·ªáu ·ª©ng d·ª•ng
- T·ªëi ∆∞u chi ph√≠
- Ph√π h·ª£p cho: H·∫ßu h·∫øt c√°c use case, ƒë·∫∑c bi·ªát v·ªõi chi ph√≠ quan tr·ªçng

##### 3. C√°c Vector Database kh√°c
- OpenSearch
- Pinecone
- Weaviate
- Milvus
- Qdrant
- V√† nhi·ªÅu h∆°n n·ªØa...

### 6.2. Architecture Pattern

```
[·ª®ng d·ª•ng] 
    ‚Üì
[Amazon Bedrock - Nova Multimodal Embeddings]
    ‚Üì
[Vector Store: S3 Vectors / OpenSearch Service]
    ‚Üì
[T√¨m ki·∫øm & Truy xu·∫•t]
```

---

## Ph·∫ßn 7: T√≠nh kh·∫£ d·ª•ng v√† Gi√° c·∫£

### 7.1. T√≠nh kh·∫£ d·ª•ng theo v√πng

**Amazon Nova Multimodal Embeddings** hi·ªán c√≥ s·∫µn tr√™n Amazon Bedrock t·∫°i:

- **Region:** US East (N. Virginia) - `us-east-1`
- **Ng√†y ra m·∫Øt:** 28 th√°ng 10, 2025

### 7.2. Gi√° c·∫£

ƒê·ªÉ bi·∫øt th√¥ng tin chi ti·∫øt v·ªÅ gi√°, vui l√≤ng truy c·∫≠p:
- üîó [Amazon Bedrock Pricing Page](https://aws.amazon.com/bedrock/pricing/)

---

## Ph·∫ßn 8: T√†i nguy√™n tham kh·∫£o

### 8.1. T√†i li·ªáu v√† Code Examples

#### T√†i li·ªáu ch√≠nh th·ª©c:
- üìò [Amazon Nova User Guide](https://docs.aws.amazon.com/nova/latest/userguide/what-is-nova.html) - T√†i li·ªáu to√†n di·ªán
- üíª [Amazon Nova Model Cookbook tr√™n GitHub](https://github.com/aws-samples/amazon-nova-samples) - V√≠ d·ª• code th·ª±c t·∫ø

### 8.2. C√¥ng c·ª• h·ªó tr·ª£ cho AI Assistants

N·∫øu b·∫°n ƒëang s·ª≠ d·ª•ng AI assistants nh∆∞ **Amazon Q Developer** ho·∫∑c **Kiro** cho ph√°t tri·ªÉn ph·∫ßn m·ªÅm, b·∫°n c√≥ th·ªÉ thi·∫øt l·∫≠p:

#### AWS API MCP Server:
- Gi√∫p AI assistant t∆∞∆°ng t√°c v·ªõi c√°c d·ªãch v·ª• v√† t√†i nguy√™n AWS
- üîó [AWS API MCP Server Documentation](https://awslabs.github.io/mcp/servers/aws-api-mcp-server)

#### AWS Knowledge MCP Server:
- Cung c·∫•p ki·∫øn th·ª©c v·ªÅ t√†i li·ªáu m·ªõi nh·∫•t, code samples, AWS API v√† CloudFormation resources
- Th√¥ng tin v·ªÅ t√≠nh kh·∫£ d·ª•ng theo region
- üîó [AWS Knowledge MCP Server Documentation](https://awslabs.github.io/mcp/servers/aws-knowledge-mcp-server)

### 8.3. H·ªó tr·ª£ v√† Ph·∫£n h·ªìi

#### Nh·∫≠n h·ªó tr·ª£:
- üí¨ [AWS re:Post for Amazon Bedrock](https://repost.aws/tags/TAQeKlaPaNRQ2tWB6P7KrMag/amazon-bedrock)
- üìß Li√™n h·ªá h·ªó tr·ª£ AWS th√¥ng th∆∞·ªùng

#### G·ª≠i ph·∫£n h·ªìi:
B·∫Øt ƒë·∫ßu s·ª≠ d·ª•ng Nova Multimodal Embeddings ngay h√¥m nay ƒë·ªÉ x√¢y d·ª±ng ·ª©ng d·ª•ng s·ª≠ d·ª•ng multimodal AI v√† g·ª≠i ph·∫£n h·ªìi c·ªßa b·∫°n!

---

## Ph·∫ßn 9: T·ªïng k·∫øt

### 9.1. C√°c ƒëi·ªÉm n·ªïi b·∫≠t ch√≠nh

‚úÖ **M√¥ h√¨nh th·ªëng nh·∫•t ƒë·∫ßu ti√™n:** H·ªó tr·ª£ text, document, image, video, audio  
‚úÖ **ƒê·ªô ch√≠nh x√°c cao:** K·∫øt qu·∫£ benchmark v∆∞·ª£t tr·ªôi  
‚úÖ **Linh ho·∫°t:** 4 dimension options (3072, 1024, 384, 256)  
‚úÖ **ƒêa ng√¥n ng·ªØ:** H·ªó tr·ª£ t·ªëi ƒëa 200 ng√¥n ng·ªØ  
‚úÖ **Segmentation:** X·ª≠ l√Ω n·ªôi dung d√†i hi·ªáu qu·∫£  
‚úÖ **Cross-modal search:** T√¨m ki·∫øm ƒëa ph∆∞∆°ng th·ª©c m·∫°nh m·∫Ω  
‚úÖ **Responsible AI:** Content safety v√† fairness measures  

### 9.2. Use Cases ch√≠nh

1. **Agentic RAG (Retrieval-Augmented Generation)**
2. **Semantic Search**
3. **Cross-modal Search** (T√¨m ki·∫øm b·∫±ng text cho image, v.v.)
4. **Reference Image Search**
5. **Visual Document Retrieval**
6. **Video Content Search**
7. **Audio Clip Search**
8. **Mixed-modal Content Analysis**

### 9.3. L·ª£i √≠ch kinh doanh

üí∞ **Gi·∫£m chi ph√≠:** M·ªôt m√¥ h√¨nh thay v√¨ nhi·ªÅu m√¥ h√¨nh chuy√™n bi·ªát  
‚ö° **TƒÉng t·ªëc ph√°t tri·ªÉn:** API ƒë∆°n gi·∫£n, d·ªÖ t√≠ch h·ª£p  
üéØ **ƒê·ªô ch√≠nh x√°c cao:** K·∫øt qu·∫£ t√¨m ki·∫øm t·ªët h∆°n  
üîÑ **Linh ho·∫°t:** T·ªëi ∆∞u chi ph√≠ v·ªõi nhi·ªÅu dimension options  
üìà **M·ªü r·ªông d·ªÖ d√†ng:** T√≠ch h·ª£p v·ªõi AWS ecosystem  

### 9.4. B·∫Øt ƒë·∫ßu ngay h√¥m nay

1. **Truy c·∫≠p Amazon Bedrock Console** trong US East (N. Virginia)
2. **Ch·ªçn Nova Multimodal Embeddings model**
3. **Th·ª≠ nghi·ªám v·ªõi text, image, video ho·∫∑c audio**
4. **T√≠ch h·ª£p v√†o ·ª©ng d·ª•ng c·ªßa b·∫°n**
5. **Tri·ªÉn khai production v·ªõi S3 Vectors ho·∫∑c OpenSearch Service**

---

## Th√¥ng tin li√™n h·ªá

**T√°c gi·∫£ b√†i vi·∫øt g·ªëc:** [Danilo Poccia](https://twitter.com/danilop)

**B√†i vi·∫øt g·ªëc (Ti·∫øng Anh):** [Amazon Nova Multimodal Embeddings now available in Amazon Bedrock](https://aws.amazon.com/jp/blogs/aws/amazon-nova-multimodal-embeddings-now-available-in-amazon-bedrock/)

**B√†i vi·∫øt ti·∫øng Nh·∫≠t:** [Amazon Nova Multimodal Embeddings - AWS Blog JP](https://aws.amazon.com/jp/blogs/news/amazon-nova-multimodal-embeddings-now-available-in-amazon-bedrock/)

---

*T√†i li·ªáu n√†y ƒë∆∞·ª£c d·ªãch t·ª´ b√†i vi·∫øt g·ªëc tr√™n AWS Blog. M·ªçi th√¥ng tin k·ªπ thu·∫≠t v√† code examples ƒë·ªÅu ƒë∆∞·ª£c gi·ªØ nguy√™n t·ª´ ngu·ªìn ch√≠nh th·ª©c.*

**¬© 2025 Amazon Web Services, Inc. ho·∫∑c c√°c c√¥ng ty li√™n k·∫øt. M·ªçi quy·ªÅn ƒë∆∞·ª£c b·∫£o l∆∞u.**
