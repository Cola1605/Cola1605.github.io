#!/usr/bin/env python3
"""
Advanced Translation Cleanup Script
Improves the quality of auto-translated content
"""

import sys
import os
import re

def clean_mixed_language_content(text):
    """Clean up mixed Vietnamese-Japanese content"""
    
    # Advanced Vietnamese to Japanese mappings
    cleanup_mappings = {
        # Fix mixed phrases
        "è¨˜äº‹ nÃ y": "ã“ã®è¨˜äº‹",
        "cá»§a AI": "ã®AI",
        "ã«ã¤ã„ã¦ AI": "AIã«ã¤ã„ã¦",
        "ä½¿ç”¨ trong": "ã§ä½¿ç”¨",
        "ä»•äº‹ã§ viá»‡c": "ä»•äº‹",
        "táº­p há»£p ãƒ’ãƒ³ãƒˆ": "ãƒ’ãƒ³ãƒˆé›†",
        "ãŸã‚ã« á»©ng dá»¥ng": "ã®ãŸã‚ã®æ´»ç”¨",
        "viá»‡c lÃ m": "ä½œæ¥­",
        
        # Complete Vietnamese phrases that weren't translated
        "chuyÃªn sÃ¢u vá» kinh nghiá»‡m": "å°‚é–€çš„ãªçµŒé¨“ã«ã¤ã„ã¦",
        "tiáº¿t lá»™ nhá»¯ng": "å…¬é–‹ã™ã‚‹",
        "tip vÃ  tricks": "ã‚³ãƒ„ã¨ãƒ†ã‚¯ãƒ‹ãƒƒã‚¯",
        "thá»±c táº¿": "å®Ÿè·µçš„",
        "nhÆ° má»™t": "ã¨ã—ã¦",
        "hÃ£y sá»­ dá»¥ng": "ä½¿ç”¨ã—ã¦ãã ã•ã„",
        "Ä‘á»ƒ á»©ng dá»¥ng": "æ´»ç”¨ã™ã‚‹ãŸã‚ã«",
        
        # Fix remaining Vietnamese words
        "nÃ y": "ã“ã®",
        "nhá»¯ng": "ã®",
        "má»™t": "ä¸€ã¤ã®",
        "cÃ¡c": "ã®",
        "cÃ³ thá»ƒ": "ã§ãã‚‹",
        "Ä‘Æ°á»£c": "ã•ã‚Œã‚‹",
        "sáº½": "ã—ã¾ã™",
        "Ä‘Ã£": "ã—ãŸ",
        "Ä‘ang": "ã—ã¦ã„ã‚‹",
        "bá»‹": "ã•ã‚Œã‚‹",
        
        # Improve sentence structure
        "ã€‚ HÃ£y": "ã€‚",
        "ã€‚ Nhá»¯ng": "ã€‚",
        "ã€‚ Äá»ƒ": "ã€‚",
        ". vá»": "ã«ã¤ã„ã¦",
        ". cá»§a": "ã®",
        ". tá»«": "ã‹ã‚‰",
        
        # Fix broken titles and headers
        "çµŒé¨“ã‚’å­¦ã¶ ä½¿ç”¨": "AI SCREAMä½¿ç”¨çµŒé¨“ã‚’å­¦ã¶",
        "å¯¾è±¡èª­è€… cá»§a": "å¯¾è±¡èª­è€…ã®",
        
        # Improve readability
        "AI SCREAM ã‚’": "AI SCREAMã‚’",
        "AI ã‚’": "AIã‚’",
        "æŠ€è¡“ ã‚’": "æŠ€è¡“ã‚’",
        "è¨˜äº‹ ã‚’": "è¨˜äº‹ã‚’",
    }
    
    cleaned_text = text
    for vietnamese, japanese in cleanup_mappings.items():
        cleaned_text = cleaned_text.replace(vietnamese, japanese)
    
    # Remove remaining Vietnamese words commonly missed
    vietnamese_words = [
        'vÃ ', 'hoáº·c', 'nhÆ°ng', 'vÃ¬', 'nÃªn', 'Ä‘á»ƒ', 'vá»›i', 'trong', 'trÃªn', 'dÆ°á»›i',
        'cá»§a', 'tá»«', 'vá»', 'cho', 'theo', 'nhÆ°', 'Ä‘Æ°á»£c', 'sáº½', 'Ä‘Ã£', 'Ä‘ang',
        'lÃ ', 'cÃ³', 'khÃ´ng', 'ráº¥t', 'nhiá»u', 'Ã­t', 'táº¥t cáº£', 'má»™t sá»‘',
        'bÃ i', 'pháº§n', 'chÆ°Æ¡ng', 'má»¥c', 'Ä‘iá»ƒm', 'phÆ°Æ¡ng phÃ¡p', 'cÃ¡ch',
        'thá»i gian', 'lÃºc', 'khi', 'sau', 'trÆ°á»›c', 'giá»¯a', 'cuá»‘i',
        'Ä‘áº§u', 'giá»¯a', 'cuá»‘i', 'hÆ¡n', 'nháº¥t', 'rá»“i', 'xong'
    ]
    
    for word in vietnamese_words:
        # Remove standalone Vietnamese words
        pattern = r'\b' + re.escape(word) + r'\b'
        cleaned_text = re.sub(pattern, '', cleaned_text, flags=re.IGNORECASE)
    
    # Clean up extra spaces and formatting
    cleaned_text = re.sub(r'\s+', ' ', cleaned_text)  # Multiple spaces to single
    cleaned_text = re.sub(r'\s*\n\s*', '\n', cleaned_text)  # Clean newlines
    cleaned_text = re.sub(r'\n\n+', '\n\n', cleaned_text)  # Multiple newlines to double
    
    return cleaned_text.strip()

def improve_japanese_structure(text):
    """Improve Japanese sentence structure"""
    
    # Common improvements for Japanese text
    improvements = {
        # Fix particles
        'ã®ã®': 'ã®',
        'ã‚’ã‚’': 'ã‚’',
        'ã«ã«': 'ã«',
        'ã¯ã¯': 'ã¯',
        'ãŒãŒ': 'ãŒ',
        
        # Fix sentence endings
        ' ã§ã™ ': 'ã§ã™',
        ' ã¾ã™ ': 'ã¾ã™',
        ' ã§ã‚ã‚‹ ': 'ã§ã‚ã‚‹',
        
        # Improve readability
        'AI SCREAMä½¿ç”¨': 'AI SCREAMã®ä½¿ç”¨',
        'AIæŠ€è¡“': 'AIæŠ€è¡“',
        'ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°è¨€èª': 'ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°è¨€èª',
        
        # Fix spacing around punctuation
        ' ã€‚': 'ã€‚',
        ' ã€': 'ã€',
        ' ï¼Ÿ': 'ï¼Ÿ',
        ' ï¼': 'ï¼',
        '( ': 'ï¼ˆ',
        ' )': 'ï¼‰',
    }
    
    improved_text = text
    for old, new in improvements.items():
        improved_text = improved_text.replace(old, new)
    
    return improved_text

def clean_translation_file(input_file, output_file=None):
    """Clean up a translated markdown file"""
    
    if output_file is None:
        output_file = input_file
    
    try:
        with open(input_file, 'r', encoding='utf-8') as f:
            content = f.read()
        
        print(f"ğŸ§¹ Cleaning translation: {input_file}")
        
        # Apply cleaning
        cleaned_content = clean_mixed_language_content(content)
        cleaned_content = improve_japanese_structure(cleaned_content)
        
        # Write output
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(cleaned_content)
        
        print(f"âœ… Cleaned translation saved: {output_file}")
        return True
        
    except Exception as e:
        print(f"âŒ Cleaning failed: {e}")
        return False

def main():
    if len(sys.argv) < 2:
        print("Usage: python3 cleanup_translation.py <input_file> [output_file]")
        sys.exit(1)
    
    input_file = sys.argv[1]
    output_file = sys.argv[2] if len(sys.argv) > 2 else None
    
    success = clean_translation_file(input_file, output_file)
    sys.exit(0 if success else 1)

if __name__ == "__main__":
    main()